{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named gensim.models.wrappers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0bc3b9a3cb95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangdetect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named gensim.models.wrappers"
     ]
    }
   ],
   "source": [
    "#Bunch of Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import glob\n",
    "from langdetect import detect\n",
    "import itertools as it\n",
    "from gensim.models.wrappers import FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data and remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Regex init\n",
    "url_regex = re.compile(\n",
    "        r'^(?:http|ftp)s?://' # http:// or https://\n",
    "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' #domain...\n",
    "        r'localhost|' #localhost...\n",
    "        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ...or ip\n",
    "        r'(?::\\d+)?' # optional port\n",
    "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "printable_chars = set(string.printable)\n",
    "punctuations = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from langdetect.detector_factory import DetectorFactory\n",
    "factory = DetectorFactory()\n",
    "factory.load_profile('/Users/apple/Desktop/swisher/analysis/langdetect/profiles/')\n",
    "\n",
    "def detect_lang(text):\n",
    "    detector = factory.create()\n",
    "    detector.append(text)\n",
    "    return detector.detect()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_non_english_tweets(df):\n",
    "    accepted_langs = ['en', 'et', 'ro', 'ca', 'sw', 'fi', 'sk', 'so', 'id', 'fr','pl', 'sv', 'hr', 'sl', 'tl', 'it', 'cy', 'sq', 'cs', 'hu']\n",
    "    lang_list = []\n",
    "    lang = \"\"\n",
    "    for i in list(df['text']):\n",
    "        try:\n",
    "            lang = detect(i) \n",
    "            lang = \"Not accepted\" if lang not in accepted_langs else lang\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        lang_list.append(lang)\n",
    "    df['lang'] = lang_list\n",
    "    #df = df[df['lang'] != False]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_tweet(tweet,lemmatize=False):\n",
    "    words = []\n",
    "    clean_tweet = ''.join(filter(lambda c: c in printable_chars, tweet))\n",
    "    for token, tag in nltk.pos_tag(tokenizer.tokenize(clean_tweet.lower())):\n",
    "        if len(token) < 2 or url_regex.search(token):\n",
    "            continue\n",
    "        elif all(char in punctuations for char in token):\n",
    "            continue\n",
    "        elif token[0] == '@':\n",
    "            token = '@person' #Replace all friend tags with a common token.\n",
    "            tag = 'NNP'\n",
    "        words.append(token)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ww', u'bro', u'love', u'swisher', u'gahdamn', '@person']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_tweet(\"ww Bro # I love swisher GAHDAMN @me\", lemmatize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    '''\n",
    "        Read the data and convert createdAt to timestamp\n",
    "        Drop cols=id, createdAt, latitude, longitude, place_country, place_name, place_type\n",
    "    '''\n",
    "    header = pd.read_csv(file_name, nrows=0)\n",
    "    df = pd.read_csv(file_name,usecols=header)\n",
    "    df['timestamp'] = pd.to_datetime(df['createdAt'],errors='coerce')\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = df[df.isRetweet == '0']\n",
    "    \n",
    "    df = df.drop(['createdAt','isRetweet','latitude','longitude', 'place_country', 'place_name', 'place_type'],axis=1)\n",
    "    df['id']=pd.to_numeric(df['id'], errors='coerce')\n",
    "    df.dropna(subset=['id'],inplace=True)\n",
    "    df['NormalizedText'] = list(map(normalize_tweet, df['text']))\n",
    "    df = filter_non_english_tweets(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "file_list = glob.glob(\"/Users/apple/Desktop/swisher/data/*.csv\")\n",
    "for fname in file_list:\n",
    "    print \"Processing:  \",fname,\n",
    "    df = read_data(fname)\n",
    "    print \"Processed:  \",fname, \"*** Count: \",len(df)\n",
    "    \n",
    "    df.to_csv('/Users/apple/Desktop/swisher/unique_tweets/'+fname.split('/')[-1], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Read unique_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame()\n",
    "file_list = glob.glob(\"/Users/apple/Desktop/swisher/unique_tweets/*.csv\")\n",
    "#file_list = [\"/Users/apple/Desktop/swisher/unique_tweets/Nov01ToNov15.csv\"]\n",
    "for fname in file_list:\n",
    "    temp = pd.read_csv(fname)\n",
    "    data_df = data_df.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>NormalizedText</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.041221e+18</td>\n",
       "      <td>Bro I love swisher GAHDAMN</td>\n",
       "      <td>3178697646</td>\n",
       "      <td>2018-09-16 00:02:05</td>\n",
       "      <td>[bro, love, swisher, gahdamn]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.041221e+18</td>\n",
       "      <td>@atendyne Its either a reg swisher or sweet ba...</td>\n",
       "      <td>2159965242</td>\n",
       "      <td>2018-09-16 00:03:01</td>\n",
       "      <td>[@person, its, either, reg, swisher, or, sweet...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.041224e+18</td>\n",
       "      <td>i just got a homie high for his first time eve...</td>\n",
       "      <td>852689860871602177</td>\n",
       "      <td>2018-09-16 00:14:09</td>\n",
       "      <td>[just, got, homie, high, for, his, first, time...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.041229e+18</td>\n",
       "      <td>Ain't get to roll no weed, ain't get to roll n...</td>\n",
       "      <td>708542839</td>\n",
       "      <td>2018-09-16 00:36:32</td>\n",
       "      <td>[ain't, get, to, roll, no, weed, ain't, get, t...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.041231e+18</td>\n",
       "      <td>I would make him look through the trash too, d...</td>\n",
       "      <td>3001624555</td>\n",
       "      <td>2018-09-16 00:43:06</td>\n",
       "      <td>[would, make, him, look, through, the, trash, ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  1.041221e+18                         Bro I love swisher GAHDAMN   \n",
       "1  1.041221e+18  @atendyne Its either a reg swisher or sweet ba...   \n",
       "3  1.041224e+18  i just got a homie high for his first time eve...   \n",
       "6  1.041229e+18  Ain't get to roll no weed, ain't get to roll n...   \n",
       "7  1.041231e+18  I would make him look through the trash too, d...   \n",
       "\n",
       "               userId           timestamp  \\\n",
       "0          3178697646 2018-09-16 00:02:05   \n",
       "1          2159965242 2018-09-16 00:03:01   \n",
       "3  852689860871602177 2018-09-16 00:14:09   \n",
       "6           708542839 2018-09-16 00:36:32   \n",
       "7          3001624555 2018-09-16 00:43:06   \n",
       "\n",
       "                                      NormalizedText lang  \n",
       "0                      [bro, love, swisher, gahdamn]   en  \n",
       "1  [@person, its, either, reg, swisher, or, sweet...   en  \n",
       "3  [just, got, homie, high, for, his, first, time...   en  \n",
       "6  [ain't, get, to, roll, no, weed, ain't, get, t...   en  \n",
       "7  [would, make, him, look, through, the, trash, ...   en  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = data_df[~data_df['lang'].isnull()]\n",
    "df = df[df['lang']!='Not accepted']\n",
    "#data_df[~((data_df['lang'].isnull())(data_df['lang']=='Not accepted')  | (data_df['lang']=='NaN'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'so', 'sv', 'sw', 'cy', 'sq', 'pl', 'tl', 'hu', 'ro', 'et',\n",
       "       'hr', 'id', 'fr', 'it', 'ca', 'sl', 'fi', 'cs', 'sk'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lang.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>NormalizedText</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.05789025932e+18</td>\n",
       "      <td>Social platforms operate with sloppy disregard...</td>\n",
       "      <td>19757554</td>\n",
       "      <td>2018-11-01 00:01:07</td>\n",
       "      <td>[u'social', u'platforms', u'operate', u'with',...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.05789072646e+18</td>\n",
       "      <td>Social platforms operate with sloppy disregard...</td>\n",
       "      <td>27365543</td>\n",
       "      <td>2018-11-01 00:02:58</td>\n",
       "      <td>[u'social', u'platforms', u'operate', u'with',...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.05789099743e+18</td>\n",
       "      <td>Social platforms operate with sloppy disregard...</td>\n",
       "      <td>2985579963</td>\n",
       "      <td>2018-11-01 00:04:03</td>\n",
       "      <td>[u'social', u'platforms', u'operate', u'with',...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.05789113735e+18</td>\n",
       "      <td>#ICanRelate\\n#MustLoveCats\\n\\nTony Swisher htt...</td>\n",
       "      <td>27611383</td>\n",
       "      <td>2018-11-01 00:04:36</td>\n",
       "      <td>[u'#icanrelate', u'#mustlovecats', u'tony', u'...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.05789156982e+18</td>\n",
       "      <td>Social platforms operate with sloppy disregard...</td>\n",
       "      <td>3309380118</td>\n",
       "      <td>2018-11-01 00:06:19</td>\n",
       "      <td>[u'social', u'platforms', u'operate', u'with',...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               text  \\\n",
       "1  1.05789025932e+18  Social platforms operate with sloppy disregard...   \n",
       "2  1.05789072646e+18  Social platforms operate with sloppy disregard...   \n",
       "3  1.05789099743e+18  Social platforms operate with sloppy disregard...   \n",
       "4  1.05789113735e+18  #ICanRelate\\n#MustLoveCats\\n\\nTony Swisher htt...   \n",
       "5  1.05789156982e+18  Social platforms operate with sloppy disregard...   \n",
       "\n",
       "       userId            timestamp  \\\n",
       "1    19757554  2018-11-01 00:01:07   \n",
       "2    27365543  2018-11-01 00:02:58   \n",
       "3  2985579963  2018-11-01 00:04:03   \n",
       "4    27611383  2018-11-01 00:04:36   \n",
       "5  3309380118  2018-11-01 00:06:19   \n",
       "\n",
       "                                      NormalizedText lang  \n",
       "1  [u'social', u'platforms', u'operate', u'with',...   en  \n",
       "2  [u'social', u'platforms', u'operate', u'with',...   en  \n",
       "3  [u'social', u'platforms', u'operate', u'with',...   en  \n",
       "4  [u'#icanrelate', u'#mustlovecats', u'tony', u'...   en  \n",
       "5  [u'social', u'platforms', u'operate', u'with',...   en  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71383"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_userid = df['userId'].unique()\n",
    "len(unique_userid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('user_id.csv', 'w') as f:\n",
    "    for id in unique_userid:\n",
    "        f.write(\"%s\\n\" % id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71383"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_userid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Process Bot users"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "bot_df = pd.DataFrame()\n",
    "file_list = glob.glob(\"/Users/apple/Desktop/swisher/bot_results/*.json\")\n",
    "count = 0\n",
    "user_id = []\n",
    "universal_score=[]\n",
    "english_score = []\n",
    "for fname in file_list:\n",
    "    data = []\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            d = json_normalize(json.loads(line))\n",
    "            if 'user.id_str' in d:\n",
    "                user_id.append(d['user.id_str'][0])\n",
    "                universal_score.append(d['scores.universal'][0])\n",
    "                english_score.append(d['scores.english'][0])\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bot_df['user_id']= user_id\n",
    "bot_df['universal_score']=universal_score\n",
    "bot_df['english_score'] = english_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>universal_score</th>\n",
       "      <th>english_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>545455886</td>\n",
       "      <td>0.052029</td>\n",
       "      <td>0.053331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>877167468</td>\n",
       "      <td>0.056245</td>\n",
       "      <td>0.067835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1042179458302717952</td>\n",
       "      <td>0.095903</td>\n",
       "      <td>0.085924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001273707493380097</td>\n",
       "      <td>0.474489</td>\n",
       "      <td>0.180767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3725024597</td>\n",
       "      <td>0.138026</td>\n",
       "      <td>0.108277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id  universal_score  english_score\n",
       "0            545455886         0.052029       0.053331\n",
       "1            877167468         0.056245       0.067835\n",
       "2  1042179458302717952         0.095903       0.085924\n",
       "3  1001273707493380097         0.474489       0.180767\n",
       "4           3725024597         0.138026       0.108277"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bot_df)\n",
    "bot_df.to_csv('bot_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>universal_score</th>\n",
       "      <th>english_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40351.000000</td>\n",
       "      <td>40351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.140096</td>\n",
       "      <td>0.130846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.190728</td>\n",
       "      <td>0.205292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.018465</td>\n",
       "      <td>0.015423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.037980</td>\n",
       "      <td>0.027678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.060780</td>\n",
       "      <td>0.041790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.128516</td>\n",
       "      <td>0.108277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.986118</td>\n",
       "      <td>0.987588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       universal_score  english_score\n",
       "count     40351.000000   40351.000000\n",
       "mean          0.140096       0.130846\n",
       "std           0.190728       0.205292\n",
       "min           0.018465       0.015423\n",
       "25%           0.037980       0.027678\n",
       "50%           0.060780       0.041790\n",
       "75%           0.128516       0.108277\n",
       "max           0.986118       0.987588"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Filter data from Bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bot_df= pd.read_csv('bot_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>universal_score</th>\n",
       "      <th>english_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>545455886</td>\n",
       "      <td>0.052029</td>\n",
       "      <td>0.053331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>877167468</td>\n",
       "      <td>0.056245</td>\n",
       "      <td>0.067835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1042179458302717952</td>\n",
       "      <td>0.095903</td>\n",
       "      <td>0.085924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001273707493380097</td>\n",
       "      <td>0.474489</td>\n",
       "      <td>0.180767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3725024597</td>\n",
       "      <td>0.138026</td>\n",
       "      <td>0.108277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id  universal_score  english_score\n",
       "0            545455886         0.052029       0.053331\n",
       "1            877167468         0.056245       0.067835\n",
       "2  1042179458302717952         0.095903       0.085924\n",
       "3  1001273707493380097         0.474489       0.180767\n",
       "4           3725024597         0.138026       0.108277"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bot_threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bot_df = bot_df[bot_df['universal_score']<=bot_threshold]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bot_df = bot_df[bot_df['english_score']<=bot_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100270, 38887)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df),len(bot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_non_bots = df[df['userId'].isin(bot_df['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54835"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_non_bots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>NormalizedText</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.06334e+18</td>\n",
       "      <td>Facebook and the Fires\" by KARA SWISHER via NY...</td>\n",
       "      <td>3057178511</td>\n",
       "      <td>2018-11-16 00:01:34</td>\n",
       "      <td>[u'facebook', u'and', u'the', u'fires', u'by',...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.06334e+18</td>\n",
       "      <td>Facebook and the Fires\" by KARA SWISHER #Opini...</td>\n",
       "      <td>3057178511</td>\n",
       "      <td>2018-11-16 00:03:39</td>\n",
       "      <td>[u'facebook', u'and', u'the', u'fires', u'by',...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.06334e+18</td>\n",
       "      <td>@HoldMyPurseGirl That nasty ass swisher got me...</td>\n",
       "      <td>46276589</td>\n",
       "      <td>2018-11-16 00:14:33</td>\n",
       "      <td>['@person', u'that', u'nasty', u'ass', u'swish...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.06335e+18</td>\n",
       "      <td>Facebook and the Fires\"  Kara Swisher on why F...</td>\n",
       "      <td>51685865</td>\n",
       "      <td>2018-11-16 00:16:23</td>\n",
       "      <td>[u'facebook', u'and', u'the', u'fires', u'kara...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.06335e+18</td>\n",
       "      <td>I’m really a swisher man</td>\n",
       "      <td>40290165</td>\n",
       "      <td>2018-11-16 00:21:41</td>\n",
       "      <td>[u'im', u'really', u'swisher', u'man']</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text      userId  \\\n",
       "0  1.06334e+18  Facebook and the Fires\" by KARA SWISHER via NY...  3057178511   \n",
       "2  1.06334e+18  Facebook and the Fires\" by KARA SWISHER #Opini...  3057178511   \n",
       "3  1.06334e+18  @HoldMyPurseGirl That nasty ass swisher got me...    46276589   \n",
       "4  1.06335e+18  Facebook and the Fires\"  Kara Swisher on why F...    51685865   \n",
       "5  1.06335e+18                           I’m really a swisher man    40290165   \n",
       "\n",
       "             timestamp                                     NormalizedText lang  \n",
       "0  2018-11-16 00:01:34  [u'facebook', u'and', u'the', u'fires', u'by',...   en  \n",
       "2  2018-11-16 00:03:39  [u'facebook', u'and', u'the', u'fires', u'by',...   en  \n",
       "3  2018-11-16 00:14:33  ['@person', u'that', u'nasty', u'ass', u'swish...   en  \n",
       "4  2018-11-16 00:16:23  [u'facebook', u'and', u'the', u'fires', u'kara...   en  \n",
       "5  2018-11-16 00:21:41             [u'im', u'really', u'swisher', u'man']   en  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_bots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_non_bots.to_csv('data_non_bots.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>NormalizedText</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20884</th>\n",
       "      <td>2213693318</td>\n",
       "      <td>426</td>\n",
       "      <td>426</td>\n",
       "      <td>426</td>\n",
       "      <td>426</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10709</th>\n",
       "      <td>338299487</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26327</th>\n",
       "      <td>3242522096</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>34923805</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26325</th>\n",
       "      <td>3242429862</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId   id  text  timestamp  NormalizedText  lang\n",
       "20884  2213693318  426   426        426             426   426\n",
       "10709   338299487  210   210        210             210   210\n",
       "26327  3242522096  203   203        203             203   203\n",
       "2361     34923805  171   171        171             171   171\n",
       "26325  3242429862  142   142        142             142   142"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_bots.groupby('userId').count().reset_index().sort_values(['text'],ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_gram(tweet_df):\n",
    "    \n",
    "    # Load the word vectors for the tweets 1-grams\n",
    "    onegram_df = pd.DataFrame(list(nltk.FreqDist(it.chain(*tweet_df.NormalizedText)).items()),\n",
    "                 columns=['Word', 'Freq'])\n",
    "    onegram_df['Tweets'] = onegram_df.Word.apply(lambda word: set())\n",
    "    onegram_df['TweetsCount'] = onegram_df.Word.apply(lambda word: 0)\n",
    "    onegram_df['IsInteresting'] = onegram_df.Word.apply(lambda word: word not in stopwords and not word.strip().isdigit())\n",
    "    print('Loading FastText model. Will take a few minutes...')\n",
    "    ft_model = FastText.load_fasttext_format(FAST_TEXT_MODEL_FILE)\n",
    "    print('FastText model loaded.')\n",
    "    onegram_df['Vector'] = list(map(lambda x: ft_model[x] if x in ft_model else np.zeros(300), onegram_df.Word))\n",
    "    onegram_df.set_index('Word', inplace=True)\n",
    "    onegram_df.sort_values(['Freq'], ascending=[False], inplace=True)\n",
    "    for i, tweet in enumerate(tweet_df.NormalizedText):\n",
    "        for word in tweet:\n",
    "            onegram_df.loc[word].Tweets.add(i)\n",
    "            onegram_df.at[word, 'TweetsCount'] = len(onegram_df.loc[word].Tweets)\n",
    "        \n",
    "    # Load the bam histogram\n",
    "    print('Processing bi-grams')\n",
    "    bigram_df = pd.DataFrame(list(nltk.FreqDist(it.chain(*map(lambda x: map('-'.join,\n",
    "                        filter(lambda bi: all(word not in stopwords and not word.strip().isdigit() for word in bi),\n",
    "                               nltk.bigrams(x))), tweet_df.NormalizedText))).items()),\n",
    "                columns=['Word', 'Freq'])\n",
    "    bigram_df['Tweets'] = bigram_df.Word.apply(lambda word: set())\n",
    "    bigram_df['TweetsCount'] = bigram_df.Word.apply(lambda word: 0)\n",
    "    bigram_df.set_index('Word', inplace=True)\n",
    "    bigram_df.sort_values(['Freq'], ascending=[False], inplace=True)\n",
    "    for i, tweet in enumerate(tweet_df.NormalizedText):\n",
    "        for bigram in filter(lambda bi: all(word not in stopwords and not word.strip().isdigit() for word in bi), nltk.bigrams(tweet)):\n",
    "            key = '-'.join(bigram)\n",
    "            bigram_df.loc[key].Tweets.add(i)\n",
    "            bigram_df.at[key, 'TweetsCount'] = len(bigram_df.loc[key].Tweets)\n",
    "    return tweet_df, onegram_df, bigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FastText model. Will take a few minutes...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'FastText' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-d468b7995fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_gram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_non_bots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-db9281931bce>\u001b[0m in \u001b[0;36mto_gram\u001b[0;34m(tweet_df)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0monegram_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'IsInteresting'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monegram_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading FastText model. Will take a few minutes...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mft_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_fasttext_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFAST_TEXT_MODEL_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FastText model loaded.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0monegram_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Vector'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mft_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mft_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monegram_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'FastText' is not defined"
     ]
    }
   ],
   "source": [
    "meh = to_gram(df_non_bots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
